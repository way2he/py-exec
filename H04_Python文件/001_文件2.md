# Python文件操作深度解析

## 1. 基本概念
### 1.1 文件对象与文件描述符
在Python中，文件操作主要通过文件对象(file object)实现。关键概念包括：

1. **文件对象**：
   - Python提供的高层抽象接口
   - 通过`open()`函数创建
   - 提供`read()`、`write()`等方法
   - 实现了上下文管理器协议

2. **文件描述符(File Descriptor)**：
   - 操作系统级别的资源标识符
   - 整数形式表示
   - 通过`fileno()`方法获取
   - 底层通过系统调用(如open、read、write)操作

3. **关系**：
   ```python
   f = open('example.txt', 'r')  # 创建文件对象
   fd = f.fileno()              # 获取文件描述符
   ```

### 1.2 文本模式与二进制模式
Python文件打开的主要模式：

| 模式 | 描述符 | 处理方式 | 适用场景 |
|------|--------|----------|----------|
| 't'  | 文本模式 | 自动编码转换(\n与系统换行符转换) | 文本文件处理 |
| 'b'  | 二进制模式 | 直接操作字节 | 非文本文件(如图片、视频) |

关键区别：
- 文本模式：
  ```python
  with open('text.txt', 'r') as f:  # 默认文本模式
      content = f.read()  # 返回str对象
  ```
  
- 二进制模式：
  ```python
  with open('image.png', 'rb') as f:
      data = f.read()  # 返回bytes对象
  ```

### 1.3 缓冲机制
Python文件操作的缓冲策略：

1. **缓冲类型**：
   - 全缓冲：缓冲区满才写入(默认)
   - 行缓冲：遇到换行符写入(如终端输出)
   - 无缓冲：直接写入(如stderr)

2. **缓冲设置**：
   ```python
   # 设置缓冲区大小(字节)
   f = open('file.txt', 'w', buffering=1024) 
   
   # 行缓冲
   f = open('file.txt', 'w', buffering=1)
   
   # 无缓冲
   f = open('file.txt', 'w', buffering=0)
   ```

3. **性能影响**：
   - 适当缓冲可减少IO操作次数
   - 但可能增加数据丢失风险(如崩溃时)
   - 关键数据建议手动flush或使用无缓冲

## 2. 核心语法与执行流程
### 2.1 文件打开与关闭
**文件打开语法**：
```python
file_object = open(
    file,                   # 文件路径
    mode='r',               # 打开模式
    buffering=-1,           # 缓冲策略
    encoding=None,          # 文本编码
    errors=None,            # 编码错误处理
    newline=None,           # 换行符处理
    closefd=True,           # 是否关闭底层描述符
    opener=None             # 自定义开启器
)
```

**常用模式组合**：
| 模式 | 描述 |
|------|------|
| 'r'  | 只读(默认) |
| 'w'  | 写入(截断) |
| 'x'  | 排他创建 |
| 'a'  | 追加 |
| 'b'  | 二进制模式 |
| 't'  | 文本模式(默认) |
| '+'  | 读写模式 |

**正确关闭文件**：
```python
# 方式1：显式关闭
f = open('file.txt')
try:
    # 操作文件
finally:
    f.close()

# 方式2：上下文管理器(推荐)
with open('file.txt') as f:
    # 操作文件
    # 自动关闭
```

### 2.2 读写操作
**读取方法**：
1. `read(size=-1)`：读取size字节，默认全部
2. `readline(size=-1)`：读取一行
3. `readlines(hint=-1)`：读取所有行

**写入方法**：
1. `write(s)`：写入字符串/字节
2. `writelines(lines)`：写入多行
3. `flush()`：强制刷新缓冲区

**示例**：
```python
# 读取示例
with open('data.txt', 'r') as f:
    chunk = f.read(1024)  # 读取1KB
    line = f.readline()   # 读取一行
    lines = f.readlines() # 读取所有行

# 写入示例
with open('output.txt', 'w') as f:
    f.write('Hello\n')  # 写入单行
    f.writelines(['Line1\n', 'Line2\n'])  # 写入多行
```

### 2.3 文件指针控制
**关键方法**：
1. `tell()`：返回当前指针位置
2. `seek(offset, whence=0)`：移动指针

**whence参数**：
- 0：从文件头开始(默认)
- 1：从当前位置开始
- 2：从文件末尾开始

**示例**：
```python
with open('data.bin', 'rb') as f:
    f.seek(10)  # 移动到第10字节
    pos = f.tell()  # 获取当前位置
    f.seek(-5, 2)  # 移动到倒数第5字节
```

### 2.4 上下文管理器
**实现原理**：
```python
class FileContextManager:
    def __init__(self, filename, mode):
        self.file = open(filename, mode)
        
    def __enter__(self):
        return self.file
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.file.close()
        return False  # 不抑制异常
```

**使用优势**：
1. 自动资源清理
2. 异常安全
3. 代码简洁

**支持多个上下文**：
```python
with open('a.txt') as f1, open('b.txt') as f2:
    # 同时操作两个文件
    # 自动按打开顺序关闭
```

## 3. 示例代码
### 3.1 基础文件操作
**文件复制**：
```python
def copy_file(src, dst):
    """基础文件复制函数"""
    with open(src, 'rb') as src_file:
        with open(dst, 'wb') as dst_file:
            dst_file.write(src_file.read())

# 使用示例
copy_file('source.txt', 'destination.txt')
```

**日志记录**：
```python
def log_message(message, logfile='app.log'):
    """追加日志消息"""
    with open(logfile, 'a') as f:
        f.write(f"[{datetime.now()}] {message}\n")

# 使用示例
log_message("System started")
```

**配置文件读取**：
```python
def read_config(config_file):
    """读取键值对配置文件"""
    config = {}
    with open(config_file) as f:
        for line in f:
            if '=' in line and not line.startswith('#'):
                key, value = line.strip().split('=', 1)
                config[key] = value
    return config

# 使用示例
config = read_config('settings.ini')
```

### 3.2 高级文件处理
**大文件逐块处理**：
```python
def process_large_file(filename, chunk_size=1024*1024):
    """逐块处理大文件"""
    with open(filename, 'rb') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            # 处理每个数据块
            yield process_chunk(chunk)
```

**CSV文件处理**：
```python
import csv

def filter_csv(input_file, output_file, condition):
    """过滤CSV文件行"""
    with open(input_file) as fin, open(output_file, 'w') as fout:
        reader = csv.DictReader(fin)
        writer = csv.DictWriter(fout, fieldnames=reader.fieldnames)
        writer.writeheader()
        for row in reader:
            if condition(row):
                writer.writerow(row)
```

**文件内容搜索**：
```python
def search_in_file(filename, pattern):
    """在文件中搜索模式"""
    with open(filename) as f:
        for line_num, line in enumerate(f, 1):
            if pattern in line:
                yield (line_num, line.strip())
```

### 3.3 性能敏感场景
**内存映射文件**：
```python
import mmap

def mmap_example(filename):
    """使用内存映射处理大文件"""
    with open(filename, 'r+b') as f:
        with mmap.mmap(f.fileno(), 0) as mm:
            # 像操作内存一样操作文件
            if mm.find(b'keyword') != -1:
                mm.seek(0)
                mm.write(b'Modified content')
```

**批量写入优化**：
```python
def batch_writer(filename, data, batch_size=1000):
    """批量写入优化"""
    with open(filename, 'w') as f:
        batch = []
        for item in data:
            batch.append(str(item))
            if len(batch) >= batch_size:
                f.write('\n'.join(batch) + '\n')
                batch = []
        if batch:  # 写入剩余部分
            f.write('\n'.join(batch))
```

**二进制文件处理**：
```python
def process_binary(filename):
    """高效二进制文件处理"""
    with open(filename, 'rb') as f:
        header = f.read(4)  # 读取文件头
        if header == b'\x89PNG':
            # 处理PNG文件
            while chunk := f.read(4096):  # Python 3.8+ 海象运算符
                process_png_chunk(chunk)
```

## 4. 适用场景
### 4.1 最佳使用场景
1. **配置文件处理**：
   - 适合场景：小型配置文件的读写
   - 推荐方式：
     ```python
     # 读取配置
     with open('config.ini') as f:
         config = json.load(f)
     
     # 写入配置
     with open('config.ini', 'w') as f:
         json.dump(config, f, indent=4)
     ```

2. **日志记录**：
   - 适合场景：应用程序运行日志
   - 推荐方式：
     ```python
     with open('app.log', 'a') as f:
         f.write(f"[{datetime.now()}] {message}\n")
     ```

3. **数据批处理**：
   - 适合场景：ETL管道中的数据处理
   - 推荐方式：
     ```python
     with open('data.csv') as fin, open('processed.csv', 'w') as fout:
         for line in fin:
             fout.write(process_line(line))
     ```

4. **二进制文件操作**：
   - 适合场景：图片、音视频等二进制文件
   - 推荐方式：
     ```python
     with open('image.png', 'rb') as f:
         header = f.read(8)  # 读取文件头识别格式
     ```

### 4.2 不推荐使用场景
1. **超大规模文件处理**：
   - 不推荐原因：内存限制
   - 替代方案：使用数据库或专门的大数据处理工具

2. **高并发写入场景**：
   - 不推荐原因：文件锁和竞争条件
   - 替代方案：使用消息队列或数据库

3. **复杂数据结构存储**：
   - 不推荐原因：维护困难
   - 替代方案：使用数据库或序列化格式(如Protocol Buffers)

4. **频繁随机访问**：
   - 不推荐原因：性能低下
   - 替代方案：使用内存数据库或缓存系统

5. **跨平台共享数据**：
   - 不推荐原因：编码和换行符问题
   - 替代方案：使用标准化数据交换格式(如JSON、XML)

## 5. 常见陷阱与规避
### 5.1 资源泄漏
**常见问题**：
1. 忘记关闭文件导致文件描述符泄漏
   ```python
   # 错误示例
   f = open('file.txt')
   # 忘记f.close()
   ```

2. 异常导致文件未关闭
   ```python
   try:
       f = open('file.txt')
       # 可能抛出异常的操作
   except:
       pass  # 文件未关闭
   ```

**解决方案**：
1. 使用上下文管理器(推荐)
   ```python
   with open('file.txt') as f:
       # 操作文件
   ```

2. 显式try-finally
   ```python
   f = open('file.txt')
   try:
       # 操作文件
   finally:
       f.close()
   ```

3. 限制同时打开的文件数
   ```python
   import resource
   resource.setrlimit(resource.RLIMIT_NOFILE, (100, 100))
   ```

### 5.2 编码问题
**常见问题**：
1. 编码不一致导致乱码
   ```python
   # 错误示例：编码不匹配
   with open('utf8.txt', 'r', encoding='gbk') as f:
       content = f.read()  # 可能乱码
   ```

2. 平台换行符差异
   ```python
   # Windows写入的\r\n在Linux显示异常
   ```

**解决方案**：
1. 明确指定编码
   ```python
   with open('file.txt', 'r', encoding='utf-8') as f:
       content = f.read()
   ```

2. 使用newline参数控制换行符
   ```python
   with open('file.txt', 'w', newline='\n') as f:
       f.write('统一换行符\n')
   ```

3. 二进制模式处理文本
   ```python
   with open('file.txt', 'rb') as f:
       content = f.read().decode('utf-8')
   ```

### 5.3 并发访问
**常见问题**：
1. 多进程/线程同时写入冲突
   ```python
   # 多个进程同时写入同一文件
   ```

2. 读取时文件被修改
   ```python
   # 读取过程中其他进程修改了文件
   ```

**解决方案**：
1. 使用文件锁
   ```python
   import fcntl
   with open('file.txt', 'w') as f:
       fcntl.flock(f, fcntl.LOCK_EX)  # 排他锁
       f.write('安全写入')
       fcntl.flock(f, fcntl.LOCK_UN)  # 释放锁
   ```

2. 临时文件+原子替换
   ```python
   import os
   with open('temp.txt', 'w') as f:
       f.write('内容')
   os.replace('temp.txt', 'target.txt')  # 原子操作
   ```

3. 避免共享文件
   ```python
   # 使用队列或数据库替代文件共享
   ```

## 6. 最佳实践
### 6.1 代码可读性
1. **使用描述性变量名**：
   ```python
   # 好
   with open('user_data.json', 'r') as user_file:
       data = json.load(user_file)
   
   # 不好
   with open('u.json', 'r') as f:
       d = json.load(f)
   ```

2. **合理封装文件操作**：
   ```python
   def load_config(config_path):
       """加载并返回配置文件内容"""
       with open(config_path) as f:
           return json.load(f)
   ```

3. **添加必要注释**：
   ```python
   # 处理大文件时使用分块读取
   CHUNK_SIZE = 1024 * 1024  # 1MB
   with open('large_file.bin', 'rb') as f:
       while chunk := f.read(CHUNK_SIZE):
           process_chunk(chunk)
   ```

### 6.2 性能优化建议
1. **批量读写**：
   ```python
   # 批量写入比单次写入高效
   with open('output.txt', 'w') as f:
       f.writelines(lines)  # 批量写入多行
   ```

2. **适当缓冲设置**：
   ```python
   # 大文件写入设置较大缓冲区
   with open('big_file.dat', 'wb', buffering=8*1024*1024) as f:
       f.write(data)
   ```

3. **内存映射优化**：
   ```python
   import mmap
   with open('large.data', 'r+b') as f:
       with mmap.mmap(f.fileno(), 0) as mm:
           # 高效随机访问大文件
           if mm.find(b'pattern') != -1:
               ...
   ```

### 6.3 异常处理
1. **处理特定异常**：
   ```python
   try:
       with open('config.ini') as f:
           config = parse_config(f)
   except FileNotFoundError:
       print("配置文件不存在，使用默认配置")
       config = default_config
   except PermissionError:
       print("无权限访问配置文件")
       raise
   ```

2. **资源清理保障**：
   ```python
   f = None
   try:
       f = open('temp.txt', 'w')
       # 可能失败的操作
   finally:
       if f is not None:
           f.close()  # 确保文件关闭
   ```

3. **上下文管理器嵌套**：
   ```python
   try:
       with open('input.txt') as fin, open('output.txt', 'w') as fout:
           for line in fin:
               fout.write(process_line(line))
   except IOError as e:
       print(f"文件操作失败: {e}")
       raise
   ```

## 7. 性能优化
### 7.1 缓冲策略
1. **缓冲区大小选择**：
   - 小文件(1MB以下)：默认缓冲即可
   - 中等文件(1MB-100MB)：设置8KB-64KB缓冲区
   - 大文件(100MB以上)：设置1MB-8MB缓冲区

2. **缓冲模式选择**：
   ```python
   # 顺序写入大文件
   with open('bigfile.dat', 'wb', buffering=8*1024*1024) as f:
       f.write(data)
   
   # 随机访问文件
   with open('random.dat', 'r+b', buffering=0) as f:
       f.seek(1024)
       data = f.read(512)
   ```

3. **手动刷新策略**：
   ```python
   with open('critical.log', 'a') as f:
       for event in events:
           f.write(f"{event}\n")
           if critical_event(event):
               f.flush()  # 确保关键事件立即写入
   ```

### 7.2 批量操作
1. **批量读取优化**：
   ```python
   # 批量读取替代单行读取
   with open('data.txt') as f:
       while lines := f.readlines(65536):  # 64KB chunks
           process_batch(lines)
   ```

2. **批量写入优化**：
   ```python
   # 批量写入减少IO次数
   BATCH_SIZE = 1000
   with open('output.txt', 'w') as f:
       batch = []
       for item in data:
           batch.append(str(item))
           if len(batch) >= BATCH_SIZE:
               f.write('\n'.join(batch) + '\n')
               batch = []
       if batch:
           f.write('\n'.join(batch))
   ```

3. **内存高效处理**：
   ```python
   # 生成器处理大文件
   def read_large_file(filename):
       with open(filename) as f:
           for line in f:
               yield process_line(line)
   
   # 使用示例
   for processed in read_large_file('huge.txt'):
       # 处理每行
   ```

### 7.3 内存映射
1. **内存映射基础**：
   ```python
   import mmap
   with open('large.data', 'r+b') as f:
       with mmap.mmap(f.fileno(), 0) as mm:
           # 像操作内存一样操作文件
           if mm.find(b'pattern') != -1:
               mm.seek(0)
               mm.write(b'new data')
   ```

2. **性能对比**：
   | 操作类型 | 传统IO | 内存映射 | 适用场景 |
   |---------|--------|----------|----------|
   | 顺序读取 | 快 | 相当 | 大文件处理 |
   | 随机访问 | 慢 | 极快 | 数据库文件 |
   | 小文件 | 快 | 开销大 | 不推荐 |

3. **高级用法**：
   ```python
   # 部分映射
   with open('huge.bin', 'r+b') as f:
       # 仅映射前100MB
       with mmap.mmap(f.fileno(), length=100*1024*1024, access=mmap.ACCESS_WRITE) as mm:
           modify_content(mm)
   
   # 共享内存映射
   mm = mmap.mmap(-1, 1024)  # 创建匿名映射
   mm.write(b'shared data')  # 可用于进程间通信
   ```

## 8. 经验总结
### 8.1 使用建议
1. **优先使用上下文管理器**：
   ```python
   # 推荐方式
   with open('file.txt') as f:
       process(f)
   
   # 避免方式
   f = open('file.txt')
   try:
       process(f)
   finally:
       f.close()
   ```

2. **明确指定编码**：
   ```python
   # 总是明确指定编码
   with open('data.txt', 'r', encoding='utf-8') as f:
       content = f.read()
   ```

3. **处理大文件的黄金法则**：
   - 使用生成器逐行/逐块处理
   - 避免一次性读取整个文件
   - 考虑内存映射技术

4. **文件路径处理建议**：
   ```python
   from pathlib import Path
   
   # 使用Path处理路径
   file_path = Path('data') / '2023' / 'sales.csv'
   with file_path.open('r') as f:
       process_csv(f)
   ```

### 8.2 项目中的实际应用案例
1. **日志轮转系统**：
   ```python
   import gzip
   from pathlib import Path
   from datetime import datetime
   
   def rotate_logs(log_dir, max_files=10):
       """日志文件轮转压缩"""
       log_dir = Path(log_dir)
       logs = sorted(log_dir.glob('*.log'), key=lambda f: f.stat().st_mtime)
       
       while len(logs) > max_files:
           oldest = logs.pop(0)
           with open(oldest, 'rb') as fin:
               with gzip.open(f"{oldest}.gz", 'wb') as fout:
                   fout.write(fin.read())
           oldest.unlink()
   ```

2. **数据ETL管道**：
   ```python
   def process_data_pipeline(source_dir, dest_dir):
       """多阶段数据ETL处理"""
       for src_file in Path(source_dir).glob('*.csv'):
           dest_file = Path(dest_dir) / src_file.name
           
           # 阶段1: 数据清洗
           with src_file.open() as fin, dest_file.open('w') as fout:
               for line in clean_data(fin):
                   fout.write(line)
           
           # 阶段2: 数据转换
           transform_data(dest_file)
   ```

3. **配置文件热加载**：
   ```python
   import time
   import hashlib
   
   def watch_config(config_file, callback):
       """监控配置文件变化并回调"""
       last_hash = None
       while True:
           with open(config_file, 'rb') as f:
               current_hash = hashlib.md5(f.read()).hexdigest()
           
           if current_hash != last_hash:
               callback(config_file)
               last_hash = current_hash
           
           time.sleep(5)  # 每5秒检查一次
   ```

4. **高效数据缓存**：
   ```python
   import pickle
   import os
   
   class DiskCache:
       """基于文件的简单缓存系统"""
       def __init__(self, cache_dir='cache'):
           self.cache_dir = Path(cache_dir)
           os.makedirs(self.cache_dir, exist_ok=True)
       
       def get(self, key):
           cache_file = self.cache_dir / f"{key}.pkl"
           if cache_file.exists():
               with cache_file.open('rb') as f:
                   return pickle.load(f)
           return None
       
       def set(self, key, value):
           cache_file = self.cache_dir / f"{key}.pkl"
           with cache_file.open('wb') as f:
               pickle.dump(value, f)
   ```

## 9. 底层原理剖析
### 9.1 CPython实现解析
1. **文件对象结构**：
   - CPython中文件对象定义在`Objects/fileobject.c`
   - 核心结构体`PyFileObject`包含：
     ```c
     typedef struct {
         PyObject_HEAD
         FILE *f_fp;                // 标准C文件指针
         PyObject *f_name;          // 文件名
         PyObject *f_mode;          // 打开模式
         int f_encoding;            // 文本编码
         int f_errors;              // 编码错误处理
         // 其他成员...
     } PyFileObject;
     ```

2. **关键函数**：
   - `PyFile_FromFd()`: 从文件描述符创建文件对象
   - `PyFile_WriteObject()`: 写入Python对象到文件
   - `file_read()`: 实现read方法的核心函数

3. **缓冲机制实现**：
   - 文本模式：通过`io.TextIOWrapper`实现编码转换
   - 二进制模式：直接操作原始字节流
   - 缓冲策略：通过`setvbuf()`设置标准库缓冲

### 9.2 系统调用分析
1. **文件打开流程**：
   ```mermaid
   graph TD
     A[Python open()] --> B[PyFile_Open]
     B --> C[PyUnicode_FSConverter]
     C --> D[os_open]
     D --> E[系统调用open]
     E --> F[创建文件描述符]
     F --> G[创建FILE*]
     G --> H[创建PyFileObject]
   ```

2. **关键系统调用**：
   - `open()`: 打开文件，返回文件描述符
   - `read()`/`write()`: 读写数据
   - `lseek()`: 移动文件指针
   - `close()`: 关闭文件描述符

3. **性能关键点**：
   - 用户态与内核态切换开销
   - 页缓存(Page Cache)利用效率
   - VFS(Virtual File System)层处理
   - 文件锁竞争处理

4. **与操作系统的交互**：
   ```python
   with open('file.txt') as f:
       # Python层
       content = f.read()
       
       # 实际执行流程：
       # 1. 调用f.read()
       # 2. 调用libc的fread()
       # 3. 触发系统调用read()
       # 4. 内核从磁盘读取数据
       # 5. 数据通过页缓存返回用户空间
   ```

## 10. 高级主题
### 10.1 异步文件IO
1. **asyncio文件操作**：
   ```python
   import asyncio
   from aiofile import AIOFile
   
   async def async_file_io():
       async with AIOFile('data.txt', 'r') as afp:
           content = await afp.read()
           print(content)
   
   # 运行示例
   asyncio.run(async_file_io())
   ```

2. **aiofiles库使用**：
   ```python
   import aiofiles
   
   async def process_large_file():
       async with aiofiles.open('bigfile.txt', mode='r') as f:
           async for line in f:
               process_line(line)
   ```

3. **性能考量**：
   - 适合高并发IO密集型应用
   - 在Linux上使用io_uring可获得最佳性能
   - Windows上使用IOCP实现

### 10.2 内存映射文件
1. **高级内存映射**：
   ```python
   import mmap
   import contextlib
   
   def search_in_mapped_file(filename, pattern):
       with open(filename, 'r+b') as f:
           with contextlib.closing(mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)) as mm:
               offset = mm.find(pattern)
               if offset != -1:
                   return offset, mm[offset:offset+100]  # 返回匹配位置和部分内容
   ```

2. **共享内存通信**：
   ```python
   # 进程1: 创建共享内存
   mm = mmap.mmap(-1, 1024)  # 创建1KB匿名映射
   mm.write(b'Hello from Process 1')
   
   # 进程2: 访问相同内存区域
   mm = mmap.mmap(-1, 1024)
   print(mm.read(20))  # 输出: b'Hello from Process 1'
   ```

3. **性能优化技巧**：
   - 使用`MAP_POPULATE`预加载文件(MAP_POPULATE)
   - 对频繁访问区域使用`madvise(MADV_SEQUENTIAL)`
   - 大文件使用`MAP_NORESERVE`

### 10.3 文件锁机制
1. **跨平台文件锁**：
   ```python
   import fcntl  # Unix
   import msvcrt  # Windows
   
   def acquire_lock(f):
       try:
           fcntl.flock(f, fcntl.LOCK_EX | fcntl.LOCK_NB)  # Unix非阻塞锁
       except (AttributeError, ImportError):
           try:
               msvcrt.locking(f.fileno(), msvcrt.LK_NBLCK, 1)  # Windows
           except (AttributeError, ImportError):
               pass  # 无锁实现
   ```

2. **锁类型对比**：
   | 锁类型 | 描述 | 适用场景 |
   |--------|------|----------|
   | 共享锁(LOCK_SH) | 多个进程可同时读 | 读多写少 |
   | 排他锁(LOCK_EX) | 独占访问 | 写操作 |
   | 非阻塞锁(LOCK_NB) | 立即返回 | 避免死锁 |

3. **分布式文件锁**：
   ```python
   import fasteners
   
   @fasteners.interprocess_locked('/tmp/lockfile')
   def safe_write():
       with open('shared.txt', 'a') as f:
           f.write('Critical section\n')
   ```

4. **锁的注意事项**：
   - 锁只在同一操作系统内有效
   - NFS等网络文件系统需要特殊处理
   - 锁的粒度影响性能
   - 必须确保锁最终会被释放

